import os.path

import jsonlines

from utils import generate
# whether the focuses of the two contexts are consistent and
hallucination_detect_prompt = lambda context1, context2, question, answer: f"""
You are an LLM hallucination detection expert. 
You will be provided with two contexts: 
one generated by asking an LLM for context related to the question,
 and another derived from an internal state analysis of what the LLM internally considers relevant to the question. 
 Although these two contexts may differ, they are both correct. 
 Based on the question, the two contexts, and the answer, 
 you need to analyze  whether the answer contradicts the first context and whether the two context contradict. 
 Based on this analysis, determine if there are any hallucinations in the answer. Think step by step, return YES if 
 hallucination exists, return NO if the answer is correct.

First Context: {context1}
Second Context: {context2}
Question: {question}
Answer: {answer}
"""


def calculate_metrics(TN, TP, FN, FP):
    # 计算准确率
    accuracy = (TP + TN) / (TP + TN + FP + FN)
    # 计算精确率
    precision = TP / (TP + FP)
    # 计算召回率
    recall = TP / (TP + FN)
    f1_score = 2 * (precision * recall) / (precision + recall)

    return {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1_score
    }


if __name__ == '__main__':
    input_file = "/Users/tom/PycharmProjects/lrp-analysis/data/databricks-dolly-15k_judged_2.jsonl"
    output_file = "/Users/tom/PycharmProjects/lrp-analysis/data/databricks-dolly-15k_judged_ablation_2.jsonl"
    TN, TP, FN, FP = 0, 0, 0, 0
    already_judged = {}
    if os.path.exists(output_file):
        with jsonlines.open(output_file) as judge_reader:
            for record in judge_reader:
                already_judged[record["context"]] = record["judge"]
    with jsonlines.open(input_file) as reader, jsonlines.open(output_file, 'a') as writer:
        for record in reader:
            context = record["context"]
            if context in already_judged.keys():
                text = already_judged[context]
            else:
                context1 = record["context_short_lrp"]
                context2 = record["context_short_llm"]
                question = record["instruction"]
                answer_to_check = record["answer"]
                text = generate(hallucination_detect_prompt(context1, context2, question, answer_to_check))
            if "yes" in text.lower():
                record["judge"] = "yes"
                if record["label"] == "CORRECT":
                    print("no hallucination, judge wrong")
                    FN += 1
                else:
                    print("exists hallucination, judge correct")
                    TN += 1
            elif "no" in text.lower():
                record["judge"] = "no"
                if record["label"] == "CORRECT":
                    print("no hallucination, judge correct")
                    TP += 1
                else:
                    print("exists hallucination, judge wrong")
                    FP += 1
            else:
                raise Exception("not sure if hallucination exists")
            if context not in already_judged.keys():
                writer.write(record)
    print(calculate_metrics(TN, TP, FN, FP))
